{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e564a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ansari/codes/spellchecker/bart/codes'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e39d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartModel, BartForConditionalGeneration, BartConfig,BartTokenizer\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60099d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63957edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 100, 524, 2051, 16866, 1512, 2], [0, 13755, 47, 8578, 17487, 2, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0]]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.prepare_seq2seq_batch(['I am fine Ansari', 'Are you okay ?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9608baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f27c2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'_name_or_path': 'facebook/bart-large-cnn', '_num_labels': 3, 'activation_dropout': 0.0, 'activation_function': 'gelu', 'add_final_layer_norm': False, 'architectures': ['BartForConditionalGeneration'], 'attention_dropout': 0.0, 'bos_token_id': 0, 'classif_dropout': 0.0, 'classifier_dropout': 0.0, 'd_model': 1024, 'decoder_attention_heads': 16, 'decoder_ffn_dim': 4096, 'decoder_layerdrop': 0.0, 'decoder_layers': 12, 'decoder_start_token_id': 2, 'dropout': 0.1, 'early_stopping': True, 'encoder_attention_heads': 16, 'encoder_ffn_dim': 4096, 'encoder_layerdrop': 0.0, 'encoder_layers': 12, 'eos_token_id': 2, 'force_bos_token_to_be_generated': True, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2, 'gradient_checkpointing': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1', '2': 'LABEL_2'}, 'init_std': 0.02, 'is_encoder_decoder': True, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}, 'length_penalty': 2.0, 'max_length': 142, 'max_position_embeddings': 1024, 'min_length': 56, 'model_type': 'bart', 'no_repeat_ngram_size': 3, 'normalize_before': False, 'num_beams': 4, 'num_hidden_layers': 12, 'output_past': True, 'pad_token_id': 1, 'prefix': ' ', 'scale_embedding': False, 'task_specific_params': {'summarization': {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 142, 'min_length': 56, 'no_repeat_ngram_size': 3, 'num_beams': 4}}, 'transformers_version': '4.2.2', 'use_cache': True, 'vocab_size': 50264}\n",
    "config = BartConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67005ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sabbir_j/anaconda3/envs/bnlp_env/lib/python3.8/site-packages/transformers/__init__.py'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e3f598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d15927e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  8332,   947,   717,  2305,    24,  1768,     5,   909,  4518,\n",
       "            11,  1263,     7,  5876,    13,   239,  2372,  2876,  3841,  1274,\n",
       "             4,    20,  4374,    16,     7,  1888,     5,   810,     9, 12584,\n",
       "             4,  9221,  5735,  7673,   916,    58,  1768,     7,    28,  2132,\n",
       "            30,     5,  2572, 10816,    61,    58,   421,     7,    94,   149,\n",
       "            23,   513, 15372,  3859,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLE_TO_SUMMARIZE = (\n",
    "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
    "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
    "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
    ")\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f9915691",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IDS = torch.cat((inputs[\"input_ids\"],inputs[\"input_ids\"]), axis=0)\n",
    "ATTN_MASK = torch.cat((inputs[\"attention_mask\"],inputs[\"attention_mask\"]), axis=0)\n",
    "LABELS = torch.cat((labels,labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "743793fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "34c7275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Slam Slam Slam geared geared Vox Voxgren Slam Slam recurrent recurrent geared geared geared Maver Maver'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "74fc432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 56])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "989100a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.2055, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(input_ids = INPUT_IDS,attention_mask = ATTN_MASK, labels = labels)\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163a38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b9c8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.argmax(out.logits, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9866de93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 50264])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.view(-1, model.config.vocab_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d93cafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cff81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c3bbd4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1000, 0.7000, 0.1000, 0.1000]]), tensor([1]), tensor(0.9732))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpuT = torch.tensor([[.1,.7,.1,.1]]).float()\n",
    "target = torch.tensor([1]).long()\n",
    "output = loss_fct(inpuT, target)\n",
    "inpuT, target, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "477a740c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152702/2635051294.py:2: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_softmax(torch.tensor([[.1,.7,.1,.1]]).float())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5732, -0.9732, -1.5732, -1.5732]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import log_softmax\n",
    "log_softmax(torch.tensor([[.1,.7,.1,.1]]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a030c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([[    0,  8332,   947,   717,  2305,    24,  1768,     5,   909,  4518,\n",
    "            11,  1263,     7,  5876,    13,   239,  2372,  2876,  3841,  1274,\n",
    "             4,    20,  4374,    16,     7,  1888,     5,   810,     9, 12584,\n",
    "             4,  9221,  5735,  7673,   916,    58,  1768,     7,    28,  2132,\n",
    "            30,     5,  2572, 10816,    61,    58,   421,     7,    94,   149,\n",
    "            23,   513, 15372,  3859,     4,     2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(article_input_ids,num_beams=4,length_penalty=2.0,max_length=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85370165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24fe92c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_192227/3712685849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m summary_txt = tokenizer.decode(torch.tensor([[    2,     0, 12133, 23334, 23334, 23334, 29247, 29247, 29247, 12113,\n\u001b[0m\u001b[1;32m      2\u001b[0m          12113, 12113, 24235, 24235, 47927, 47927, 47927, 24235, 24235,     2]]), skip_special_tokens=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "summary_txt = tokenizer.decode(torch.tensor([[    2,     0, 12133, 23334, 23334, 23334, 29247, 29247, 29247, 12113,\n",
    "         12113, 12113, 24235, 24235, 47927, 47927, 47927, 24235, 24235,     2]]), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6566f",
   "metadata": {},
   "source": [
    "# Loss niye khela kori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8fca29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss_fct = CrossEntropyLoss()\n",
    "softmax = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6ea90fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000e-05, 9.9999e-01]]), tensor([1]), tensor(0.3133))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpuT = torch.tensor([[0.00001,1-0.00001]]).float()\n",
    "target = torch.tensor([1]).long()\n",
    "output = loss_fct(inpuT, target)\n",
    "inpuT, target, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cdca87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
