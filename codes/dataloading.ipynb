{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac3a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnvocab import Vocabulary , bn_tokenizer, normalizeText\n",
    "import numpy as np, pickle, time, pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "798baddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "bpe = BPEmb(lang=\"bn\", vs=200000, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e25a17f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1524, 11407, 10402, 1272, 49923, 48300, 22531, 14827, 49816, 39488, 49999]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"আজ আমার , ''মন? ভালো । ,নাই,২৩  ৪৩ ২ ε\"\n",
    "bpe.encode_ids(\"\".join(bn_tokenizer(sent)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df125b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁আজ', '▁আমার', '▁মন', '▁ভালো', '▁নাই', '00', '▁00', '▁0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.encode(\" \".join(bn_tokenizer(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23dc190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁আজ', '▁আমার', '▁মন', '▁ভালো', '▁নাই', '00', '▁00', '▁0']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.encode(((sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd69b1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10,  3,  8])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = bn_tokenizer(sent)\n",
    "n_tokens = int(0.25*len(tokens))\n",
    "n_tokens\n",
    "np.random.choice(range(len(tokens)), n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e3c0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = tokens.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b41a98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class wow:\n",
    "    def __init__(self):\n",
    "        self.n = 10\n",
    "    def a(self):\n",
    "        return \"A\",self.n\n",
    "    def b(self):\n",
    "        return \"B\",self.n\n",
    "    def c(self):\n",
    "        return \"C\",self.n\n",
    "    def baal(self):\n",
    "        ob = np.random.choice([self.a,self.b,self.c])\n",
    "        return ob()\n",
    "ab = wow()\n",
    "ab.baal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "506f56a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 2, 0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(np.random.choice(range(len(tokens)), 3, replace=False),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e45ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আজ', 'আমার', ',', \"'\", \"'\", 'মন', '?', 'ভালো', '।', ',', 'নাই', ',', '২৩', '৪৩', '২', 'ε']\n",
      "['আজ', 'আমার', ',', \"'\", \"'\", 'মন', 'ভালো', '।', ',', 'নাই', ',', '২৩', '৪৩', '২', 'ε']\n",
      "\n",
      "['আজ', 'আমার', ',', \"'\", \"'\", 'মন', 'ভালো', '।', ',', 'নাই', ',', '২৩', '৪৩', '২', 'ε']\n",
      "['আজ', 'আমার', \"'\", \"'\", 'মন', 'ভালো', '।', ',', 'নাই', ',', '২৩', '৪৩', '২', 'ε']\n",
      "\n",
      "['আজ', 'আমার', \"'\", \"'\", 'মন', 'ভালো', '।', ',', 'নাই', ',', '২৩', '৪৩', '২', 'ε']\n",
      "['আমার', \"'\", \"'\", 'মন', 'ভালো', '।', ',', 'নাই', ',', '২৩', '৪৩', '২', 'ε']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for  x in [6,2,0]:\n",
    "    print(tokens)\n",
    "    del tokens[x]\n",
    "    print(tokens)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f90f4921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "spans_to_mask = list(np.random.poisson(3, 1000))\n",
    "max(spans_to_mask), spans_to_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "88f05d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.poisson(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae4d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Loaded {type(data)} from {path}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7791168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded <class 'list'> from /home/ansari/codes/spellchecker/synthetic_data_for_grammar/data/pickeled_data/train_data.0.pickle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "prototype = 2000\n",
    "path = \"/home/ansari/codes/spellchecker/synthetic_data_for_grammar/data/pickeled_data/\"\n",
    "file_id = 0\n",
    "file = f\"train_data.{file_id}.pickle\"\n",
    "file_path = os.path.join(path,file)\n",
    "train_data = load_pickle(file_path)\n",
    "train_data = [(a,b) for (x,y,a,b) in train_data]\n",
    "valid_data = train_data[-1000:]\n",
    "train_data = train_data[:prototype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e89bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded <class 'list'> from /home/ansari/codes/spellchecker/synthetic_data_for_grammar/data/pickeled_data/AAAAALL_DATA_for_seq2seq.pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "186.58099054096965"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.perf_counter()\n",
    "file_path = \"/home/ansari/codes/spellchecker/synthetic_data_for_grammar/data/pickeled_data/AAAAALL_DATA_for_seq2seq.pickle\"\n",
    "train_data = load_pickle(file_path)\n",
    "time.perf_counter()-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7546647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$Start এছাড়া আমরা আমাদের গেস্টদের , আগমন - নির্গমন যথাসম্ভব গোপন রাখতে সচেষ্ট থাকি ।',\n",
       " '$Start এছাড়া আমরা আমাদের গেস্টরাশিও , আগমন - নির্গমণ যথাসম্ভব গোপন রাখতে সচেষ্ট থাকাই ;')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.choice(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54ee3dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'এছাড়া আমরা আমাদের গেস্টদের , আগমন - নির্গমন যথাসম্ভব গোপন রাখতে সচেষ্ট থাকি ।'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'$Start এছাড়া আমরা আমাদের গেস্টদের , আগমন - নির্গমন যথাসম্ভব গোপন রাখতে সচেষ্ট থাকি ।'[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c39ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$Start বিশ্বকাপে অংশ নেয়া ৩২টি দেশের মধ্যে সাতটিই রয়েছে মুসলিম প্রধান দেশ ।',\n",
       " '$Start বিশ্বকাপে অংশ নেয়া ৩২টি দেশেএরও মধ্যে সাতটিকৃত রয়েছে মুসলিম প্রধান দেশি ।')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06fc4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers:\n",
      "\n",
      "read_csv(filepath_or_buffer: Union[str, pathlib.Path, IO[~AnyStr]], sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal: str = '.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparseable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and\n",
      "        `filepath_or_buffer` is path-like, then detect compression from the\n",
      "        following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      "        decompression). If using 'zip', the ZIP file must contain only one data\n",
      "        file to be read in. Set to None for no decompression.\n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned.\n",
      "    warn_bad_lines : bool, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are `None` for the ordinary converter,\n",
      "        `high` for the high-precision converter, and `round_trip` for the\n",
      "        round-trip converter.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772f84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/annotated_sentences_v123.csv\")\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ea3db7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>content</th>\n",
       "      <th>corrected_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [document_id, content, corrected_content]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['corrected_content'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ce4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = BPEmb(lang=\"bn\", vs=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9709f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(row['document_id'], row[\"content\"],row[\"corrected_content\"] ) for i,row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a34b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15e5371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188610\n",
      "’ এদিকে সম্প্রতি প্রকাশিত এক তালিকায় পণ্যের দূতিয়ালিতে সফল বলিউড তারকাদের মধ্যে প্রথম ও দ্বিতীয় স্থান দখল করেছেন রণবীর ও কারিনা।\n",
      "nan\n",
      "'float' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "for i,(idx, trg_sent, src_sent) in enumerate(data):\n",
    "    try:\n",
    "        input_ids = bpe.encode_ids(src_sent)\n",
    "        input_ids = [1]+input_ids[:512]+[2]\n",
    "        labels = bpe.encode_ids(trg_sent)\n",
    "        labels = labels[:512] + [2]\n",
    "        decoder_input_ids = [1] + labels[:-1]\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        print(trg_sent)\n",
    "        print(src_sent)\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a1bb098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68632"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,79756)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "633cc537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appo = [(i,e,c) for (i,e,c) in data if(('\"' in e))]\n",
    "len(appo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c4ffcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(151042,\n",
       "  'এই সংকলনের \"\"দ্য কিলার্স\"\", \"\"হিলস লাইক হোয়াইট এলিফ্যান্টস\"\", ও \"\"ইন অ্যানাদার কান্ট্রি\"\" গল্পগুলোকে হেমিংওয়ের সেরা কাজ বলে গণ্য করা হয়।',\n",
       "  'এই সংকলনের \"\"দ্য কিলার্স\"\", \"\"হিলস লাইক হোয়াইট এলিফ্যান্টস\"\" ও \"\"ইন অ্যানাদার কান্ট্রি\"\" গল্পগুলোকে হেমিংওয়ের সেরা কাজ বলে গণ্য করা হয়।'),\n",
       " (207107,\n",
       "  'সমালোচক তরণ আদর্শ বলেন, \"\"রবীনা ট্যান্ডন একজন আঘাতে জর্জরিত স্ত্রীর ভূমিকার বিশ্বাসযোগ্য চিত্রায়ন দেখিয়েছেন এবং সম্মানের সাথে তা করে গেছেন।',\n",
       "  'সমালোচক তরণ আদর্শ বলেন, \"রবীনা ট্যান্ডন একজন আঘাতে জর্জরিত স্ত্রীর ভূমিকার বিশ্বাসযোগ্য চিত্রায়ন দেখিয়েছেন এবং সম্মানের সাথে তা করে গেছেন\\'\\'।'),\n",
       " (392581,\n",
       "  'প্রতিবাদী ভিন্নমত পোষণকারী\"\" বলতে সেই সমস্ত এসবিএনআরদেরকে বোঝায় যারা এর সাথে ব্যক্তিগত বিরূপ অভিজ্ঞতার কারণে ধর্মীয় অনুষঙ্গকে \\'বন্ধ\\' করা দেয়।',\n",
       "  'প্রতিবাদী ভিন্নমত পোষণকারী\"\" বলতে সেই সমস্ত এসবিএনআরদেরকে বোঝায় যারা এর সাথে ব্যক্তিগত বিরূপ অভিজ্ঞতার কারণে ধর্মীয় অনুষঙ্গকে \\'বন্ধ\\' করে দেয়।'),\n",
       " (392581,\n",
       "  'অভিবাসী\"\" বলতে সেই সমস্ত এসবিএনআরদেরকে বোঝায় যারা মূলত নতুন আধ্যাত্মিক পরিবেশের \"\"চেষ্টা\"\" করছেন তবে এখনও সেখানে পুরোপুরি স্থিতি বোধ করেনি।',\n",
       "  '\"\"অভিবাসী\"\" বলতে সেই সমস্ত এসবিএনআরদেরকে বোঝায়, যারা মূলত নতুন আধ্যাত্মিক পরিবেশের \"\"চেষ্টা\"\" করছেন, তবে এখনও সেখানে পুরোপুরি স্থিতি বোধ করেনি।'),\n",
       " (351301,\n",
       "  '২০০৮ সালের জানুয়ারিতে, রুশ, বেলারুশিয় এবং ইউক্রেনিয় শিক্ষাবিদরা বৈজ্ঞানিক ও সাংস্কৃতিক জ্ঞানের পণ্ডিত্যপূর্ণ যোগাযোগের উন্মুক্ত প্রবেশাধিকার সমর্থনে \"\"বেলগোরড ঘোষণা\"\" জারি করেছিলেন।',\n",
       "  '২০০৮ সালের জানুয়ারিতে, রুশ, বেলারুশিয় ও ইউক্রেনিয় শিক্ষাবিদরা বৈজ্ঞানিক ও সাংস্কৃতিক জ্ঞানের পণ্ডিত্যপূর্ণ যোগাযোগের উন্মুক্ত প্রবেশাধিকার সমর্থনে \"\"বেলগোরড ঘোষণা\"\" জারি করেছিলেন।'),\n",
       " (244803,\n",
       "  'যদি এটি একসময় হেনরি কিসিঞ্জারের কথিত \"\"খালি বাক্স\"\" না হয়, তবে এটি মুজিবের স্বপ্ন দেখা সোনার বাংলাও হয়ে যায় নি।',\n",
       "  'যদি এটি একসময় হেনরি কিসিঞ্জারের কথিত \"\"খালি বাক্স\"\" না হয়, তবে এটি মুজিবের স্বপ্ন দেখা সোনার বাংলাও হয়ে যায়নি।'),\n",
       " (340805,\n",
       "  '[৪] নিজের নামে থাকা \"\"কাপরেকার ধ্রুবক\"\" ও \"\"কাপরেকার সংখ্যা\"\"র বাইরে তিনি স্বয়ং সংখ্যা, হর্ষদ সংখ্যা ও ডেমলো সংখ্যা নিয়েও গবেষণা করেছিলেন।',\n",
       "  '[৪] নিজের নামে থাকা \"\"কাপরেকার ধ্রুবক\"\" ও \"\"কাপরেকার সংখ্যা\"\" এর বাইরে তিনি স্বয়ং সংখ্যা, হর্ষদ সংখ্যা ও ডেমলো সংখ্যা নিয়েও গবেষণা করেছিলেন।'),\n",
       " (415558,\n",
       "  'পারস্পরিক সমঝোতার ভিত্তিতে যদি উদ্দেশ্যপ্রণোদিতভাবে এধরনের বিয়ে দেয়া হয় তাহলে তাকে \"\"হালালা বিয়ে\"\" (আঞ্চলিকভাবে কোথাও \"\"হিল্লা/হিলা বিয়ে\"\") বলা হয়।',\n",
       "  'পারস্পরিক সমঝোতার ভিত্তিতে যদি উদ্দেশ্যপ্রণোদিতভাবে এ ধরনের বিয়ে দেয়া হয় তাহলে তাকে \"\"হালালা বিয়ে\"\" (আঞ্চলিকভাবে কোথাও \"\"হিল্লা/হিলা বিয়ে\"\") বলা হয়।'),\n",
       " (368837,\n",
       "  'ঐতিহাসিক লুকাজ কামিয়েনস্কি বলেছেন, \"\"পারভিটিন ব্যবহারকারী একজন সৈনিক সাধারণত পরের দিন বা দুই দিনের জন্য কাজ করতে অক্ষম হয়ে থাকত।',\n",
       "  'ঐতিহাসিক লুকাজ কামিয়েনস্কি বলেছেন, \"\"পারভিটিন ব্যবহারকারী একজন সৈনিক সাধারণত পরের দিন বা দুই দিনের জন্য কাজ করতে অক্ষম হয়ে থাকত\"\"।'),\n",
       " (424390,\n",
       "  '[৬] ২০০৫ সালের অক্টোবরে তিনি অভিনেতা পর্থিবনের সাথে জয়া টিভি\\'র আয়োজিত ইলাইয়ারাজার লাইভ কনসার্ট \"\"আন্ড্রুম ইন্ড্রুম এন্ড্রুম\"\" সঞ্চালনা করেন।',\n",
       "  '[৬] ২০০৫ সালের অক্টোবরে তিনি অভিনেতা পর্থিবনের সাথে জয়া টিভির আয়োজিত ইলাইয়ারাজার লাইভ কনসার্ট \"\"আন্ড্রুম ইন্ড্রুম এন্ড্রুম\"\" সঞ্চালনা করেন।')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appo[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fd8b14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.251968503937007"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7379*100/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73e08672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16807\n",
      "Correct:  এ ছেলেটি যে এরকম হবে না তার কোনো গ্যারান্টি দেশের প্রচলিত আইন দিতে পারবে কি ?\n",
      "Error  :  এ ছেলেটি যে এরকম হবে না তার কোন গ্যারান্টি দেশরে প্রচলিত আইন দিতে পারবে কি ?\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0,79756)\n",
    "(i,err,corr) = data[idx]\n",
    "print(idx)\n",
    "print(\"Correct: \",corr)\n",
    "print(\"Error  : \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7923618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pandas as pd\n",
    "with open(\"/home/ansari/codes/spellchecker/sentencepiece/database/all_words.csv\") as f:\n",
    "    lines = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e4a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnvocab import normalizeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb17f4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type() takes 1 or 3 arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83449/3103638768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: type() takes 1 or 3 arguments"
     ]
    }
   ],
   "source": [
    "for x in lines:\n",
    "    print(type(*x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d44ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "bpe = BPEmb(model_file=\"/home/ansari/codes/spellchecker/sentencepiece/character_seq_200.model\",emb_file=\"/home/ansari/codes/spellchecker/sentencepiece/character_seq_200w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "424f1aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '্র',\n",
       " 'য়',\n",
       " 'ার',\n",
       " '্য',\n",
       " '▁প',\n",
       " '▁স',\n",
       " '▁ব',\n",
       " 'ান',\n",
       " '্ত',\n",
       " 'ের',\n",
       " '▁ক',\n",
       " '▁অ',\n",
       " '▁ম',\n",
       " 'র্',\n",
       " 'িক',\n",
       " 'িত',\n",
       " 'াল',\n",
       " '▁ন',\n",
       " '্ব',\n",
       " '▁আ',\n",
       " '▁দ',\n",
       " 'ড়',\n",
       " 'ন্',\n",
       " 'ুল',\n",
       " 'াত',\n",
       " 'াই',\n",
       " 'াম',\n",
       " 'াব',\n",
       " 'াস',\n",
       " 'াক',\n",
       " '▁গ',\n",
       " 'ির',\n",
       " 'িল',\n",
       " '▁জ',\n",
       " '▁শ',\n",
       " '▁প্র',\n",
       " 'ায়',\n",
       " '▁চ',\n",
       " '্ট',\n",
       " '▁র',\n",
       " '▁ত',\n",
       " 'িয়',\n",
       " 'কে',\n",
       " '▁ভ',\n",
       " '্ষ',\n",
       " '▁হ',\n",
       " 'াদ',\n",
       " 'গুল',\n",
       " '▁উ',\n",
       " 'িন',\n",
       " 'াপ',\n",
       " 'তি',\n",
       " '▁বি',\n",
       " 'টি',\n",
       " 'রা',\n",
       " 'েন',\n",
       " '▁ল',\n",
       " '▁ফ',\n",
       " 'বি',\n",
       " '্প',\n",
       " '▁খ',\n",
       " 'াহ',\n",
       " 'াজ',\n",
       " 'ঙ্',\n",
       " 'ুক',\n",
       " 'িস',\n",
       " 'ক্ষ',\n",
       " 'ুর',\n",
       " '▁এ',\n",
       " '্থ',\n",
       " '্যা',\n",
       " 'গুলো',\n",
       " 'েছ',\n",
       " '্ল',\n",
       " 'েশ',\n",
       " 'দ্',\n",
       " 'ন্দ',\n",
       " 'েল',\n",
       " 'তা',\n",
       " 'াঁ',\n",
       " 'প্র',\n",
       " 'েই',\n",
       " 'দের',\n",
       " 'টা',\n",
       " 'কার',\n",
       " 'াগ',\n",
       " 'ন্ত',\n",
       " '▁ধ',\n",
       " '▁ই',\n",
       " 'রি',\n",
       " '▁ছ',\n",
       " '▁য',\n",
       " 'ষ্ট',\n",
       " 'য়া',\n",
       " 'নি',\n",
       " 'চ্',\n",
       " '্ম',\n",
       " 'ঙ্গ',\n",
       " '▁ট',\n",
       " '▁নি',\n",
       " '▁ড',\n",
       " '▁সম',\n",
       " 'র্ম',\n",
       " 'েও',\n",
       " '্ড',\n",
       " 'না',\n",
       " 'ুম',\n",
       " 'ৃত',\n",
       " 'োগ',\n",
       " 'ানো',\n",
       " 'সম',\n",
       " '▁ঘ',\n",
       " 'ঞ্',\n",
       " '্তি',\n",
       " 'ত্র',\n",
       " 'ীয়',\n",
       " '▁অন',\n",
       " 'দ্ধ',\n",
       " 'চ্ছ',\n",
       " 'াট',\n",
       " 'রণ',\n",
       " 'স্ত',\n",
       " 'াড়',\n",
       " 'ুন',\n",
       " 'র্ব',\n",
       " '্ন',\n",
       " 'িম',\n",
       " '▁সং',\n",
       " 'সহ',\n",
       " 'েট',\n",
       " '্ক',\n",
       " 'স্থ',\n",
       " 'ীর',\n",
       " 'ীন',\n",
       " 'জন',\n",
       " 'াশ',\n",
       " 'িতে',\n",
       " 'েক',\n",
       " '▁',\n",
       " 'া',\n",
       " '্',\n",
       " 'র',\n",
       " 'ি',\n",
       " 'ন',\n",
       " 'ে',\n",
       " 'ক',\n",
       " 'ত',\n",
       " 'ব',\n",
       " 'স',\n",
       " 'য',\n",
       " 'ল',\n",
       " 'ম',\n",
       " 'প',\n",
       " 'ু',\n",
       " 'দ',\n",
       " '়',\n",
       " 'ট',\n",
       " 'ো',\n",
       " 'গ',\n",
       " 'ী',\n",
       " 'শ',\n",
       " 'জ',\n",
       " 'হ',\n",
       " 'ই',\n",
       " 'চ',\n",
       " 'ড',\n",
       " 'ভ',\n",
       " 'ষ',\n",
       " 'ধ',\n",
       " 'ণ',\n",
       " 'অ',\n",
       " '-',\n",
       " 'ও',\n",
       " 'ছ',\n",
       " 'খ',\n",
       " 'আ',\n",
       " 'থ',\n",
       " 'ূ',\n",
       " 'ফ',\n",
       " 'ং',\n",
       " 'উ',\n",
       " 'ঁ',\n",
       " 'ৃ',\n",
       " 'এ',\n",
       " 'ঙ',\n",
       " 'ঠ',\n",
       " 'ঘ',\n",
       " 'ঞ',\n",
       " 'ৌ',\n",
       " 'ৎ',\n",
       " 'ৈ',\n",
       " 'ঝ',\n",
       " 'ঢ',\n",
       " 'ঃ',\n",
       " '’',\n",
       " 'ঋ',\n",
       " 'ঐ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6da2b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = bpe.encode(\" তিনি আরও বলেন, ‘যাঁরা শোডাউন দিয়ে বিশৃঙ্খলা সৃষ্টি করবেন, কাজের স্বাভাবিক পরিবেশে বিঘ্ন ঘটাবেন, তাঁদের দলীয় মনোনয়ন দেওয়া হবে না'। Error : তিনি আরও বলেন, ‘যাঁরা শোডাউন দিয়ে বিশৃঙ্খলা সৃষ্টি করবেন, কাজের স্বাভাবিক পরিবেশে বিঘ্ন ঘটাবেন, তাঁদের দলীয় মনোনয়ন দেওয়া হবে না। Should be : তিনি আরও বলেন, ‘যাঁরা শোডাউন দিয়ে বিশৃঙ্খলা সৃষ্টি করবেন, কাজের স্বাভাবিক পরিবেশে বিঘ্ন ঘটাবেন, তাঁদের দলীয় মনোনয়ন দেওয়া হবে না’।\")\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f8c029c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁ত',\n",
       " 'ব',\n",
       " 'ে',\n",
       " '▁ত',\n",
       " 'িন',\n",
       " 'ি',\n",
       " '▁ব',\n",
       " 'ল',\n",
       " 'েন',\n",
       " '▁',\n",
       " ',',\n",
       " '▁আ',\n",
       " 'ম',\n",
       " 'ি',\n",
       " '▁',\n",
       " ',',\n",
       " '▁',\n",
       " \"'\",\n",
       " 'য',\n",
       " 'াই',\n",
       " '▁আ',\n",
       " 'র',\n",
       " '▁ন',\n",
       " 'া',\n",
       " '▁য',\n",
       " 'াই',\n",
       " '।',\n",
       " '▁ত',\n",
       " 'ুম',\n",
       " 'ি',\n",
       " '▁য',\n",
       " 'াব',\n",
       " 'া',\n",
       " '▁',\n",
       " '?',\n",
       " '▁',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.encode(\"তবে তিনি বলেন , আমি , 'যাই আর না যাই। তুমি যাবা ? '\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2927075",
   "metadata": {},
   "source": [
    "Correct       :  তিনি আরও বলেন, ‘যাঁরা শোডাউন দিয়ে বিশৃঙ্খলা সৃষ্টি করবেন, কাজের স্বাভাবিক পরিবেশে বিঘ্ন ঘটাবেন, তাঁদের দলীয় মনোনয়ন দেওয়া হবে না'।\n",
    "Error         :  তিনি আরও বলেন, ‘যাঁরা শোডাউন দিয়ে বিশৃঙ্খলা সৃষ্টি করবেন, কাজের স্বাভাবিক পরিবেশে বিঘ্ন ঘটাবেন, তাঁদের দলীয় মনোনয়ন দেওয়া হবে না।\n",
    "Should be     :  তিনি আরও বলেন, ‘যাঁরা শোডাউন দিয়ে বিশৃঙ্খলা সৃষ্টি করবেন, কাজের স্বাভাবিক পরিবেশে বিঘ্ন ঘটাবেন, তাঁদের দলীয় মনোনয়ন দেওয়া হবে না’।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/sabbir_j/codes/BERT-MLM-FINAL-PHASE/data/sentence_queue_20220830.csv\",sep=\"\\t\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
